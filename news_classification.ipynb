{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "#nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    #remove punctuation\n",
    "    text = [char for char in text if char not in string.punctuation] \n",
    "    text_join = ''.join(text)\n",
    "    \n",
    "    #remove stopwords\n",
    "    text_join_clean = [word for word in text_join.split() if word.lower() not in stopwords.words('english')] \n",
    "    \n",
    "    #shorten word to their stem\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    stemmed_words = [stemmer.stem(word) for word in text_join_clean]\n",
    "    text_join_clean = \" \".join(stemmed_words)\n",
    "\n",
    "    \n",
    "    #return\n",
    "    return text_join_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('Articles.csv',encoding='latin-1')\n",
    "X = news_df.Article.apply(clean_text)\n",
    "y = news_df.NewsType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as model_selection\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(X_train, open('X_train.pkl', 'wb'))\n",
    "pickle.dump(y_train, open('y_train.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_test, open('X_test.pkl', 'wb'))\n",
    "pickle.dump(y_test, open('y_test.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "X_train = pickle.load(open('X_train.pkl', 'rb'))\n",
    "y_train = pickle.load(open('y_train.pkl', 'rb'))\n",
    "\n",
    "X_test = pickle.load(open('X_test.pkl', 'rb'))\n",
    "y_test = pickle.load(open('y_test.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vector as features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count Vector as features\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(X_train)\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "X_train_count = count_vect.transform(X_train)\n",
    "X_test_count = count_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-Idf Vectors as Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tf-Idf Vectors as Features\n",
    "\n",
    "# word level - we choose max number of words equal to 1000 except all words (100k+ words)\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', max_features=1000)\n",
    "tfidf_vect.fit(X_train) # learn vocabulary and idf from training set\n",
    "\n",
    "X_train_tfidf =  tfidf_vect.transform(X_train)\n",
    "\n",
    "# assume that we don't have test set before\n",
    "X_test_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['business', 'sports'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Label Encoder\n",
    "from sklearn import preprocessing\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train_n = encoder.fit_transform(y_train)\n",
    "y_test_n = encoder.fit_transform(y_test)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes and SVM with Count Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes,metrics,svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_count,y_train)\n",
    "y_predict_train = clf.predict(X_train_count)\n",
    "y_predict_test = clf.predict(X_test_count)\n",
    "#y_predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9932508436445444\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score( y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.99      1.00      0.99       424\n",
      "      sports       1.00      0.99      0.99       465\n",
      "\n",
      "    accuracy                           0.99       889\n",
      "   macro avg       0.99      0.99      0.99       889\n",
      "weighted avg       0.99      0.99      0.99       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_Positive: 460\n",
      "True_Negative: 423\n",
      "False_Positive: 1\n",
      "False_Negative: 5\n"
     ]
    }
   ],
   "source": [
    "cfs = confusion_matrix(y_test,y_predict_test)\n",
    "# True Positives\n",
    "TP = cfs[1, 1]\n",
    "print('True_Positive:' ,TP)\n",
    "# True Negatives\n",
    "TN = cfs[0, 0]\n",
    "print('True_Negative:' ,TN)\n",
    "# False Positives\n",
    "FP = cfs[0, 1]\n",
    "print('False_Positive:' ,FP)\n",
    "# False Negatives\n",
    "FN = cfs[1, 0]\n",
    "print('False_Negative:' ,FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_count,y_train)\n",
    "y_pred = model.predict(X_test_count)\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.99      0.99      0.99       424\n",
      "      sports       0.99      0.99      0.99       465\n",
      "\n",
      "    accuracy                           0.99       889\n",
      "   macro avg       0.99      0.99      0.99       889\n",
      "weighted avg       0.99      0.99      0.99       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9898762654668166\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_Positive: 461\n",
      "True_Negative: 419\n",
      "False_Positive: 5\n",
      "False_Negative: 4\n"
     ]
    }
   ],
   "source": [
    "cfs = confusion_matrix(y_test,y_pred)\n",
    "# True Positives\n",
    "TP = cfs[1, 1]\n",
    "print('True_Positive:' ,TP)\n",
    "# True Negatives\n",
    "TN = cfs[0, 0]\n",
    "print('True_Negative:' ,TN)\n",
    "# False Positives\n",
    "FP = cfs[0, 1]\n",
    "print('False_Positive:' ,FP)\n",
    "# False Negatives\n",
    "FN = cfs[1, 0]\n",
    "print('False_Negative:' ,FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive-Bayes and SMV with tf-idf vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive-Bayes\n",
    "clf.fit(X_train_tfidf,y_train)\n",
    "y_predict_train_tfidf = clf.predict(X_train_tfidf)\n",
    "y_predict_test_tfidf = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.98      0.99      0.99       424\n",
      "      sports       0.99      0.98      0.99       465\n",
      "\n",
      "    accuracy                           0.99       889\n",
      "   macro avg       0.99      0.99      0.99       889\n",
      "weighted avg       0.99      0.99      0.99       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_predict_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9865016872890888\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score( y_test, y_predict_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_Positive: 458\n",
      "True_Negative: 419\n",
      "False_Positive: 5\n",
      "False_Negative: 7\n"
     ]
    }
   ],
   "source": [
    "cfs = confusion_matrix(y_test,y_predict_test_tfidf)\n",
    "# True Positives\n",
    "TP = cfs[1, 1]\n",
    "print('True_Positive:' ,TP)\n",
    "# True Negatives\n",
    "TN = cfs[0, 0]\n",
    "print('True_Negative:' ,TN)\n",
    "# False Positives\n",
    "FP = cfs[0, 1]\n",
    "print('False_Positive:' ,FP)\n",
    "# False Negatives\n",
    "FN = cfs[1, 0]\n",
    "print('False_Negative:' ,FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMV\n",
    "model.fit(X_train_tfidf,y_train)\n",
    "y_pred_train_tfidf = model.predict(X_train_tfidf)\n",
    "y_pred_test_tfidf = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    business       0.98      1.00      0.99       424\n",
      "      sports       1.00      0.98      0.99       465\n",
      "\n",
      "    accuracy                           0.99       889\n",
      "   macro avg       0.99      0.99      0.99       889\n",
      "weighted avg       0.99      0.99      0.99       889\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test,y_pred_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9898762654668166\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score( y_test, y_pred_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_Positive: 458\n",
      "True_Negative: 422\n",
      "False_Positive: 2\n",
      "False_Negative: 7\n"
     ]
    }
   ],
   "source": [
    "cfs = confusion_matrix(y_test,y_pred_test_tfidf)\n",
    "# True Positives\n",
    "TP = cfs[1, 1]\n",
    "print('True_Positive:' ,TP)\n",
    "# True Negatives\n",
    "TN = cfs[0, 0]\n",
    "print('True_Negative:' ,TN)\n",
    "# False Positives\n",
    "FP = cfs[0, 1]\n",
    "print('False_Positive:' ,FP)\n",
    "# False Negatives\n",
    "FN = cfs[1, 0]\n",
    "print('False_Negative:' ,FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4. Evaluate the model with Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score for naive-bayes : [0.9962963  1.         0.9962963  1.         0.99256506 0.98513011\n",
      " 0.99628253 0.99256506 0.99626866 0.98880597]\n",
      "cross_val_score for SVM: [0.9962963  1.         0.9962963  1.         0.99256506 0.99628253\n",
      " 0.98141264 0.98513011 0.99626866 0.99626866]\n"
     ]
    }
   ],
   "source": [
    " from sklearn.model_selection import KFold, cross_val_score\n",
    " kf = KFold(n_splits=5, shuffle=False)\n",
    "# print(kf)\n",
    " count_vect.fit(X)\n",
    " X_count = count_vect.transform(X)\n",
    " scores1 = cross_val_score(clf, X_count, y, cv=10, scoring='accuracy')\n",
    " scores2 = cross_val_score(model, X_count, y, cv=10, scoring='accuracy')\n",
    " print('cross_val_score for naive-bayes :',scores1)\n",
    " print('cross_val_score for SVM:',scores2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score for naive-bayes : [0.9962963  1.         0.99259259 0.99259259 0.98513011 0.98513011\n",
      " 0.98141264 0.98884758 0.99253731 0.98134328]\n",
      "cross_val_score for SVM: [0.9962963  1.         0.9962963  0.99259259 0.98513011 0.99256506\n",
      " 0.98884758 0.99256506 0.99626866 0.98880597]\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect.fit(X) \n",
    "X_tfidf =  tfidf_vect.transform(X)\n",
    "scores1 = cross_val_score(clf, X_tfidf, y, cv=10, scoring='accuracy')\n",
    "scores2 = cross_val_score(model, X_tfidf, y, cv=10, scoring='accuracy')\n",
    "print('cross_val_score for naive-bayes :',scores1)\n",
    "print('cross_val_score for SVM:',scores2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
